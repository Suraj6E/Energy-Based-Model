{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Image Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display images\n",
    "def show_image(img, title=\"Image\", cmap=None):\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction using ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(image_path):\n",
    "    # Load a pretrained ResNet model\n",
    "    model = resnet50(pretrained=True)\n",
    "    model.eval()\n",
    "\n",
    "    # Define a transform to preprocess the input image\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path)\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # Create a mini-batch as expected by the model\n",
    "\n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        features = model(input_batch)\n",
    "\n",
    "    # Extract features from the last fully connected layer\n",
    "    feature_vector = features.squeeze().numpy()\n",
    "    print(\"Feature vector shape:\", feature_vector.shape)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection using Sobel Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_detection(image_path):\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "    preprocess = transforms.ToTensor()\n",
    "    input_tensor = preprocess(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Define the Sobel operator kernels\n",
    "    sobel_x = torch.tensor([[-1., 0., 1.],\n",
    "                            [-2., 0., 2.],\n",
    "                            [-1., 0., 1.]]).unsqueeze(0).unsqueeze(0)\n",
    "    sobel_y = torch.tensor([[-1., -2., -1.],\n",
    "                            [0., 0., 0.],\n",
    "                            [1., 2., 1.]]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    # Apply Sobel operators\n",
    "    grad_x = F.conv2d(input_tensor, sobel_x, padding=1)\n",
    "    grad_y = F.conv2d(input_tensor, sobel_y, padding=1)\n",
    "\n",
    "    # Calculate the gradient magnitude\n",
    "    grad_magnitude = torch.sqrt(grad_x**2 + grad_y**2).squeeze().numpy()\n",
    "\n",
    "    return grad_magnitude"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
